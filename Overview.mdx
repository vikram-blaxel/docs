---

title: 'Blaxel Documentation'

description: 'Welcome to Blaxel!'

sidebarTitle: "Overview"

---

Blaxel is a **perpetual sandbox platform built for AI agents**. Our platform lets you keep infinite, secure sandboxes on automatic standby while co-hosting your agents for near instant latency.

<Frame>
<img src="/img/general/overview-2025-05.png" />
</Frame>

An *AI agent* is any application that leverages generative AI models to take autonomous actions in the real world. These agents often require computing power to execute their interactions.

Some examples of agents include:

- **Conversational agents** that are able to take action in the world while keeping a human in the loop for activation or validation: for example code generation agents with real-time previews.
- **AI-powered data pipelines**: for example a data transformation pipeline that retrieves unstructured video files and uses an AI model to extract structured data then act on it.
- **RAG agents**: for example, a chatbot assistant that can better answer consumers’ queries by autonomously running scripts to access a relevant databases.
- **Autonomous system agents** that handle machine-to-machine workflows: like a smart traffic monitoring system that analyzes video feeds, detects accidents in real-time, and automatically dispatches emergency services with AI-generated incident reports.

Blaxel’s infrastructure platform gives production-grade agents their own computing environments including code sandboxes, tool servers, and LLMs. It offers infrastructure to run these agents on a global network that makes them run fast and reliably.

This website provides comprehensive documentation and API, SDK and CLI references to help you work with Blaxel.

## Essential concepts

Blaxel is a perpetual sandbox platform designed for agentic AI. It **doesn't force you into any kind of workflow** or shaped box. While we encourage you to exploit architecture designs that we consider are more reliable, our toolkit gives you all the pieces you need to build reliable agentic systems exactly the way you want.

Blaxel consists of modular services that are engineered to work seamlessly together, but you can also just use any one of them independently. Think of it as a purpose-built set of building blocks that you can use to power agents.

### The building blocks

At the heart of Blaxel is our flagship **perpetual sandbox** service. Sandboxes are secure, instant-launching compute environments that you can use for running AI code. Blaxel lets you keeps sandboxes on automatic standby with optimized agent hosting for near instant latency.

With Blaxel sandboxes, you get:

- Automatic scale-to-zero after 5s inactivity, resume from standby under 25ms even after weeks.
- microVMs with full access to file system, processes and logs — and native support for Zero Data Retention (ZDR).
- Preview URLs with your own custom domain.

You can co-locate agent APIs, MCP servers, and batch tasks directly alongside your sandboxes to eliminate network hops and ensure the lowest possible end-to-end latency. For this, Blaxel also offers:

- **Agents Hosting** - Deploy your AI agents as serverless auto scalable endpoints. Completely framework agnostic: just bring your code, Blaxel builds it and runs it for you.
- **Batch Jobs** - Scalable compute engine designed for agents to schedule and execute many AI processing tasks in parallel in the background
- **MCP Servers Hosting** - Deploy custom tool servers on a fast-starting infrastructure to extend your agents' capabilities.
- **Model Gateway** - Intelligent routing layer to LLM providers with built-in telemetry, token cost control, and fallbacks capabilities
- **Full observability** - out-of-the-box

### A cloud built for agents

Agents will transform how we work in the coming years. Traditional cloud providers weren't designed to handle them and their one-size-fits-all architecture holds them back. We built Blaxel to fix that.

Blaxel is a cloud where **AI agents themselves are the primary users**. All products are accessible through [MCP servers](MCP-server), allowing agents to create and manage resources via tool calls. Blaxel provides agents with all the compute they need to scale and perform optimally: products like Sandboxes give them their own dedicated personal computer(s) / computing environments, while Batch Jobs enable them to schedule background tasks at scale.

<Accordion title="The Blaxel method">
Unlike traditional sandbox providers, Blaxel Sandboxes automatically scale up and down at near-instant speeds. As such, here are some recommended best practices:

- If the end-user or agent is expected to continue a session soon, just leave the sandbox be. It will automatically suspend when the connection closes (= you will stop paying for compute runtime) and resume when reconnected.
- The definition of "soon" is at your discretion. It's a tradeoff between instant resume times from standby mode (~25ms) and paying for the [standby snapshot storage cost](https://blaxel.ai/pricing). As a rule of thumb, most customers keep sandboxes in standby for a few hours to a few days.
- Blaxel doesn't limit how long a sandbox can stay in standby mode, but doesn't guarantee data persistence. For guaranteed long-term data persistence, use [volumes](Volumes).
- If you persist data in a volume, you can delete the sandbox. To resume a session, you'll need to re-create the sandbox (~2–4 seconds) and restart processes to restore the same state.
- For automatic cleanup, set TTLs when creating your sandbox to delete it after a set idle duration or maximum age.
- When you delete a sandbox, all data is immediately erased. If the sandbox was never in standby mode, Blaxel guarantees ZDR (zero data retention).

We also recommend more general best-practices aiming to provide guardrails and framing when you build your agents - from our experience working with top AI teams.

- Break down and distribute your agents whenever possible. A single monolithic agent handling all tool calls, LLM calls, and task workflows can be deployed to Blaxel Agents Hosting - but it will be harder to maintain, monitor, and will use resources inefficiently. Blaxel SDK allows builders to split services and connect them from your code.
- Similarly, while direct tool calls are possible, deploying separate MCP servers improves reusability, optimizes resources, and simplifies monitoring. Blaxel also optimizes placement globally when your serverless tool server needs to make multiple backend calls.

</Accordion>

### Which component should I use?

When building your agentic system, you'll need to make architecture design choices. Blaxel offers several high-perf compute options, summarized below in order of latency performance:

- [**Sandboxes**](Sandboxes/Overview): Perfect for maximum workload flexibility. These microVMs provide full access to filesystem, network, and processes, booting from standby in under 25ms.
- [**Agents Hosting (sync mode)**](https://docs.blaxel.ai/Agents/Query-agents#default-synchronous-endpoint): Ideal for running HTTP API services that process requests within a few seconds.
- [**Agents Hosting (async mode)**](https://docs.blaxel.ai/Agents/Query-agents#async-endpoint): Best for running HTTP API services handling longer requests without maintaining an open connection.
- [**Batch Jobs**](Jobs/Overview): Designed for asynchronous tasks that may run for extended periods where boot latency is less critical. These jobs are triggered by providing specific input parameters, unlike Agents that are a fully hosted API.

| **Product** | **Typical use** | **Typical workload duration** | **Boot time** | **Input type** |
| --- | --- | --- | --- | --- |
| Sandboxes | Giving an agent its own compute runtime | seconds to hours | ~25ms (from standby) | Fully custom |
| Agents Hosting (sync mode) | Agent API that answers fast | a few seconds (**maximum 100 s**) | ~25ms | Custom API endpoints |
| Agents Hosting (async mode) | Agent API that processes data for a while | a few minutes (**maximum 10 mins**) | ~25ms | Custom API endpoints |
| Batch Jobs | Sub-tasks scheduled in an agentic workflow | minutes to hours (**maximum 24 h**) | ~30s | Specific input parameters |
| MCP Servers Hosting | Running an MCP server API | seconds to minutes (**maximum 10 mins**) | ~25ms | API following MCP  |

## The Blaxel powerhouse

When you deploy workloads to Blaxel, they run on a technical backbone called the **Global Agentics Network**. Its natively serverless architecture automatically scales computing resources without any server management on your part.

Global Agentics Network serves as the powerhouse for the entire Blaxel platform, from Agents Hosting to Sandboxes. It is natively **distributed** in order to optimize for low-latency or other strategies. It allows for multi-region deployment, enabling AI workloads (such as an AI agent processing inference requests) to run across multiple geographic areas or cloud providers. This is accomplished by decoupling this execution layer from a data layer made of a smart distributed network that federates all those execution locations.

Finally, the platform implements advanced security measures, including fine-grained authentication and authorization through Blaxel IAM, ensuring that your AI infrastructure remains protected. It can be interacted with through various methods, including APIs, CLI, web console, and MCP servers.

## Documentation structure

You might want to start with any of the following articles:

- [**Get started**](Get-started): Deploy your first workload on Blaxel in just 3 minutes.
- **Product Documentation**
    - [**Sandboxes**](Sandboxes/Overview): Equip your agents with fast & secure virtual machines to run AI code.
    - [**Agents Hosting**](Agents/Overview): Host and run AI agents as serverless auto-scalable endpoints.
    - [**Batch jobs**](Jobs/Overview): Background tasks for your AI workflows that run in batches.
    - [**MCP Servers Hosting**](Functions/Overview): Expose capabilities and execute tool calls using MCP.
    - [**Model APIs:**](Models/Overview) Learn about supported model types on our global AI gateway.
    - [**Integrations:**](Integrations/HuggingFace) Discover how Blaxel works with other tools, frameworks, and platforms.
    - [**Observability**](Observability/Overview): Monitor logs, traces and metrics for your agent runs.
    - [**Policies Governance**](Model-Governance/Policies)[:](Model-Governance/Environments) Manage your AI deployment strategies.
    - [**Security:**](Security/Workspace-access-control) Implement robust security measures for your AI infrastructure.
    - [**Regions**](Infrastructure/Regions): Discover where Blaxel is available in the world.
- [**API reference:**](https://docs.blaxel.ai/api-reference/introduction) Comprehensive guide to Blaxel's APIs.
- [**CLI reference:**](https://docs.blaxel.ai/cli-reference/introduction) Learn how to use Blaxel's command-line interface.
